{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "74e734ce",
      "metadata": {
        "id": "74e734ce"
      },
      "source": [
        "# Text classification: classify spam email and non-spam email by LSTM model and BERT model in Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8762eaee",
      "metadata": {
        "id": "8762eaee"
      },
      "source": [
        "Confirm that TensorFlow is using the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "67f0cc88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67f0cc88",
        "outputId": "4c5b13b1-86e5-41d2-d3bb-5f03fedc8b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Number of GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"The Number of GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cf7f9c56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf7f9c56",
        "outputId": "c12a5c34-def8-4a6e-de2e-5abac02e70e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy import *\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from transformers import TFBertModel, BertTokenizer, TFBertForSequenceClassification, BertConfig\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from keras import callbacks\n",
        "from keras.layers import Dropout\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from nltk.classify.util import accuracy\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import time\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8e6353f0",
      "metadata": {
        "id": "8e6353f0"
      },
      "outputs": [],
      "source": [
        "directory = '/content/sample_data'\n",
        "os.chdir(directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9a75d7da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9a75d7da",
        "outputId": "3dd03821-ba92-4841-c285-4f0caa26e9bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        v1                                                 v2\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham              Will Ì_ b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72bfaa02-b43b-4e68-ad8e-740100796000\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72bfaa02-b43b-4e68-ad8e-740100796000')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-72bfaa02-b43b-4e68-ad8e-740100796000 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-72bfaa02-b43b-4e68-ad8e-740100796000');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b2aa0c14-037d-44f2-8a25-1241abbef62a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2aa0c14-037d-44f2-8a25-1241abbef62a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b2aa0c14-037d-44f2-8a25-1241abbef62a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Read the dataframe\n",
        "\n",
        "df = pd.read_csv('Spam-Classification.csv')\n",
        "df.iloc[:,0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "287f1671",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "287f1671",
        "outputId": "a9d60c0b-239b-4098-dd91-24e7cb41421f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Label encoding\n",
        "\n",
        "label = LabelEncoder().fit_transform(df.iloc[:,0])\n",
        "label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40bf002d",
      "metadata": {
        "id": "40bf002d"
      },
      "source": [
        "# Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed5c7955",
      "metadata": {
        "id": "ed5c7955"
      },
      "source": [
        "Remove or replace meaningless data using regular expressions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b99a95c1",
      "metadata": {
        "id": "b99a95c1"
      },
      "outputs": [],
      "source": [
        "message=df.iloc[:,1].str.lower().copy()\n",
        "\n",
        "message=message.str.replace(r'[^ ]+@[^\\.]*(\\.[a-z]{2,}){1,2}', 'emailaddress', regex=True)\n",
        "message=message.str.replace(r'(?:http\\:\\/\\/|www.){1}(?:http\\:\\/\\/|www.)?(?![www])[a-zA-Z0-9\\-]+(\\.[a-zA-Z]{2,3}){1,2}(\\/[^/& ]+)*', 'webaddress', regex=True)\n",
        "message=message.str.replace(r'(£|\\$|€|¥|₣|å£){1}\\d+(.\\d+)?', 'money', regex=True)\n",
        "message=message.str.replace(r'\\b\\+?\\d{1}[\\d\\s-]{5,13}\\d{1}\\b|\\b[\\d]{4}[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}\\b', 'phonenumber', regex=True)\n",
        "\n",
        "# date\n",
        "# day/month/year\n",
        "message=message.str.replace(r'\\b(3[01]|[12][0-9]|[0]?[1-9]){1}[\\ |\\-|\\/]{1}(1[0-2]|[0]?[1-9]){1}[\\ |\\-|\\/]{1}(\\d{2}|\\d{4})(?!\\d{3})\\b', 'date', regex=True)\n",
        "# year/month/day\n",
        "message=message.str.replace(r'\\b(\\d{2}|\\d{4})(?!\\d{3})[\\ |\\-|\\/]{1}(1[0-2]|[0]?[1-9]){1}[\\ |\\-|\\/]{1}(3[01]|[12][0-9]|[0]?[1-9]){1}\\b', 'date', regex=True)\n",
        "# day/month(english)/year\n",
        "message=message.str.replace(r'\\b(3[01]|[12][0-9]|[0]?[1-9]){1}([\\ ]|st|nd|rd|th){1,2}(jan(?:uary)?|feb(?:ruary)?|mar(?:ch)?|apr(?:il)?|may|jun(?:e)?|jul(?:y)?|aug(?:ust)?|sep(?:tember)?|oct(?:ober)?|nov(?:ember)?|dec(?:ember)?){1}\\b(?:([\\ ]|,){0,2}(\\d{4}|\\d{2}))?\\b', 'date', regex=True)\n",
        "# month(english)/day/year\n",
        "message=message.str.replace(r'\\b(jan(?:uary)?|feb(?:ruary)?|mar(?:ch)?|apr(?:il)?|may|jun(?:e)?|jul(?:y)?|aug(?:ust)?|sep(?:tember)?|oct(?:ober)?|nov(?:ember)?|dec(?:ember)?){1}[\\ ]?(3[01]|[12][0-9]|[0]?[1-9]){1}((?: )?st|(?: )?nd|(?: )?rd|(?: )?th){0,1}(?:([\\ ]|,){0,2}(\\d{4}|\\d{2}))?\\b', 'date', regex=True)\n",
        "\n",
        "\n",
        "message=message.str.replace(r'\\b\\d+\\b', 'number', regex=True)\n",
        "message=message.str.replace(r'[^\\w\\d\\s]+', ' ', regex=True)\n",
        "message=message.str.replace(r'\\s+', ' ', regex=True)\n",
        "message=message.str.replace(r'^\\s+|\\s+?$', '', regex=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa442cba",
      "metadata": {
        "id": "aa442cba"
      },
      "source": [
        "Remove remove common words like 'a', 'the' using stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "64fb0307",
      "metadata": {
        "id": "64fb0307"
      },
      "outputs": [],
      "source": [
        "common_words=set(stopwords.words('english'))\n",
        "\n",
        "message=message.apply(lambda m: ' '.join(word for word in m.split() if word not in common_words))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "708be91e",
      "metadata": {
        "id": "708be91e"
      },
      "source": [
        "Change the form of words like 'running' to 'run' using Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "009ab7a1",
      "metadata": {
        "id": "009ab7a1"
      },
      "outputs": [],
      "source": [
        "def convert_pos(tag):\n",
        "    if tag in ['JJ', 'JJR', 'JJS']:\n",
        "        return wordnet.ADJ\n",
        "    elif tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']:\n",
        "        return wordnet.VERB\n",
        "    elif tag in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
        "        return wordnet.NOUN\n",
        "    elif tag in ['RB', 'RBR', 'RBS']:\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "def convert_pos_2(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9d38defe",
      "metadata": {
        "id": "9d38defe"
      },
      "outputs": [],
      "source": [
        "for i in range(len(message)):\n",
        "    tokens = word_tokenize(message[i])\n",
        "    tagged = pos_tag(tokens)\n",
        "\n",
        "    tokens_list_tokenized = []\n",
        "\n",
        "    for tag in tagged:\n",
        "        wordnet_pos = convert_pos(tag[1])\n",
        "        tokens_list_tokenized.append(WordNetLemmatizer().lemmatize(tag[0], pos=wordnet_pos))\n",
        "\n",
        "    tokens_to_string = ' '.join(tokens_list_tokenized)\n",
        "    message[i]=tokens_to_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0cd1fa67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cd1fa67",
        "outputId": "efc7c00a-0bbc-4b41-f4e3-0fa4841026cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mail before cleaning:  go until jurong point, crazy.. available only in bugis n great world la e buffet... cine there got amore wat... \n",
            "\n",
            "Mail after cleaning:  go jurong point crazy available bugis n great world la e buffet cine get amore wat\n"
          ]
        }
      ],
      "source": [
        "i=0\n",
        "print('Mail before cleaning: ', df.iloc[i,1].lower(), '\\n')\n",
        "print('Mail after cleaning: ', message[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1c1867b",
      "metadata": {
        "id": "e1c1867b"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d335704",
      "metadata": {
        "id": "1d335704"
      },
      "source": [
        "Count the total tokens of all data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "de4ff81e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de4ff81e",
        "outputId": "41a8482d-ee6e-4ecc-ba6e-349981c71a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of Token: 7008\n"
          ]
        }
      ],
      "source": [
        "all_words = []\n",
        "\n",
        "for m in message:\n",
        "    words = word_tokenize(m)\n",
        "    for w in words:\n",
        "        all_words.append(w)\n",
        "\n",
        "all_words = nltk.FreqDist(all_words)\n",
        "\n",
        "print('Total number of Token:', len(all_words))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbff3484",
      "metadata": {
        "id": "dbff3484"
      },
      "source": [
        "Shuffle data and split data into training set and testing set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f6dbd1cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6dbd1cb",
        "outputId": "d621dc5d-00f5-474f-8a91-612455725d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of training data:  4457\n",
            "The number of testing data:  1115\n"
          ]
        }
      ],
      "source": [
        "df_message = list(zip(message, label))\n",
        "\n",
        "\n",
        "np.random.shuffle(df_message)\n",
        "\n",
        "message_split = [text[0] for text in df_message]\n",
        "list_label = [text[1] for text in df_message]\n",
        "\n",
        "x_training, x_test, y_training, y_test= train_test_split(message_split, list_label, test_size=0.2, random_state=1)\n",
        "\n",
        "print('The number of training data: ', len(x_training))\n",
        "print('The number of testing data: ', len(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb793b9b",
      "metadata": {
        "id": "cb793b9b"
      },
      "source": [
        "Tokenized all the words and choose the 1500 most common words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "aa974cf4",
      "metadata": {
        "id": "aa974cf4"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words = 500, char_level = False, oov_token = '<OOV>')\n",
        "tokenizer.fit_on_texts(x_training)\n",
        "\n",
        "x_training_sequences = tokenizer.texts_to_sequences(x_training)\n",
        "x_test_sequences = tokenizer.texts_to_sequences(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23bc174d",
      "metadata": {
        "id": "23bc174d"
      },
      "source": [
        "Find the max len of words of all messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "22001bae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22001bae",
        "outputId": "82c0031a-3e5b-4cdc-cf43-5dbc1a6d6d55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The max len of words of all messages:  78\n"
          ]
        }
      ],
      "source": [
        "max_len=0\n",
        "\n",
        "for i in range(len(x_training_sequences)):\n",
        "    if len(x_training_sequences[i])>max_len:\n",
        "        max_len=len(x_training_sequences[i])\n",
        "\n",
        "for i in range(len(x_test_sequences)):\n",
        "    if len(x_test_sequences[i])>max_len:\n",
        "        max_len=len(x_test_sequences[i])\n",
        "\n",
        "print('The max len of words of all messages: ', max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eb3a026",
      "metadata": {
        "id": "6eb3a026"
      },
      "source": [
        "Using pad_sequences turns all the messages with same len of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3b93999e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b93999e",
        "outputId": "4b9ba7f5-5e0a-4437-aaa4-89c641a54e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of training data:  (4457, 78)\n",
            "The shape of testing data:  (1115, 78)\n"
          ]
        }
      ],
      "source": [
        "x_training_padded = pad_sequences(x_training_sequences, maxlen = max_len, padding='pre', truncating='pre')\n",
        "x_test_padded = pad_sequences(x_test_sequences, maxlen = max_len, padding='pre', truncating='pre')\n",
        "\n",
        "print('The shape of training data: ', x_training_padded.shape)\n",
        "print('The shape of testing data: ', x_test_padded.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "410f0b8d",
      "metadata": {
        "id": "410f0b8d"
      },
      "source": [
        "# Class imbalance problem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26378310",
      "metadata": {
        "id": "26378310"
      },
      "source": [
        "The dataset has a class imbalance problem, the number data with class ham is larger than the number data with class spam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "10824550",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10824550",
        "outputId": "7e4af2e4-eb21-4c40-cf7e-9ffc80605558"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ham     4825\n",
              "spam     747\n",
              "Name: v1, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df.iloc[:,0].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "058e7f9a",
      "metadata": {
        "id": "058e7f9a"
      },
      "source": [
        "Therefore, calculate the class weights by using sklearn.utils.class_weight.compute_class_weight as the class_weight parameter for training model to solve the class imbalance problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ab3bb3d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab3bb3d6",
        "outputId": "2d2cbaf2-1b81-4667-8e0f-49a61a947f13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.5768832513590474, 1: 3.7516835016835017}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "class_weights = compute_class_weight(class_weight='balanced',classes=np.unique(y_training), y=y_training)\n",
        "class_weight_dic = {0: class_weights[0], 1: class_weights[1]}\n",
        "class_weight_dic"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8da8ecb7",
      "metadata": {
        "id": "8da8ecb7"
      },
      "source": [
        "# Hyperparameter optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af9019ee",
      "metadata": {
        "id": "af9019ee"
      },
      "source": [
        "Using Grid Search to optimize the two hyperparameters: neurons and batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "905e25b2",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "905e25b2",
        "outputId": "0edc3536-d2b0-4474-8ce9-caaa014a02d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time used: 1092.16 seconds\n",
            "\n",
            "The optimized hyperparameters are: \n",
            "{'batch_size': 512, 'epochs': 30, 'model__neurons': 512}\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "def create_model(neurons):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=500, output_dim=neurons, input_length=max_len))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(LSTM(neurons, return_sequences=True))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(LSTM(neurons))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(units=(neurons/2), activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "neurons = [128, 256, 512]\n",
        "batch_size = [256, 512]\n",
        "epochs = [30]\n",
        "hypara_dict = dict(model__neurons=neurons, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "class_weights = compute_class_weight(class_weight='balanced',classes=np.unique(y_training), y=y_training)\n",
        "class_weight_dic = {0: class_weights[0], 1: class_weights[1]}\n",
        "\n",
        "keras_model = KerasRegressor(model=create_model, verbose=0)\n",
        "grid_model = GridSearchCV(estimator=keras_model, param_grid=hypara_dict, n_jobs=1, cv=3)\n",
        "grid_model.fit(x_training_padded, array(y_training),\n",
        "               validation_data = (x_test_padded, array(y_test)),\n",
        "               class_weight=class_weight_dic)\n",
        "\n",
        "print('time used: ' + str(round(time.time() - start, 2)) + ' seconds')\n",
        "print('')\n",
        "print('The optimized hyperparameters are: ')\n",
        "print(grid_model.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d6488e5",
      "metadata": {
        "id": "7d6488e5"
      },
      "source": [
        "# Train lstm model using the optimal hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22ddcc2a",
      "metadata": {
        "id": "22ddcc2a"
      },
      "source": [
        "1. Using callbacks techniques:\n",
        "    \n",
        "    callbacks.EarlyStopping: Stop model training when a monitored metric has stopped improving in 10 Epoch\n",
        "        \n",
        "    callbacks.ModelCheckpoint: Save a model and weights in a checkpoint file at some interval\n",
        "\n",
        "        \n",
        "2. Using class_weight parameter when doing model fitting to solve the class imbalance problem"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#crete the lstm model using the best hyperparameters\n",
        "\n",
        "best_parameter_lstm_model=create_model(grid_model.best_params_['model__neurons'])\n",
        "best_parameter_lstm_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfuIlxM1xDKJ",
        "outputId": "8c2f9505-1ab5-4f0f-dfe0-ba6b52ce9d1d"
      },
      "id": "wfuIlxM1xDKJ",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_19 (Embedding)    (None, 78, 512)           256000    \n",
            "                                                                 \n",
            " dropout_76 (Dropout)        (None, 78, 512)           0         \n",
            "                                                                 \n",
            " lstm_38 (LSTM)              (None, 78, 512)           2099200   \n",
            "                                                                 \n",
            " dropout_77 (Dropout)        (None, 78, 512)           0         \n",
            "                                                                 \n",
            " lstm_39 (LSTM)              (None, 512)               2099200   \n",
            "                                                                 \n",
            " dropout_78 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_79 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4585985 (17.49 MB)\n",
            "Trainable params: 4585985 (17.49 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "eac8a5eb",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eac8a5eb",
        "outputId": "bfd5e97b-1d05-4f7e-de10-3dbe6a6317cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "9/9 - 9s - loss: 0.5725 - accuracy: 0.7689 - val_loss: 0.6681 - val_accuracy: 0.7363 - 9s/epoch - 960ms/step\n",
            "Epoch 2/30\n",
            "9/9 - 3s - loss: 0.3277 - accuracy: 0.8517 - val_loss: 0.1631 - val_accuracy: 0.9525 - 3s/epoch - 320ms/step\n",
            "Epoch 3/30\n",
            "9/9 - 3s - loss: 0.1386 - accuracy: 0.9675 - val_loss: 0.1080 - val_accuracy: 0.9677 - 3s/epoch - 339ms/step\n",
            "Epoch 4/30\n",
            "9/9 - 3s - loss: 0.0796 - accuracy: 0.9800 - val_loss: 0.1105 - val_accuracy: 0.9650 - 3s/epoch - 325ms/step\n",
            "Epoch 5/30\n",
            "9/9 - 3s - loss: 0.0570 - accuracy: 0.9823 - val_loss: 0.0670 - val_accuracy: 0.9830 - 3s/epoch - 339ms/step\n",
            "Epoch 6/30\n",
            "9/9 - 3s - loss: 0.0418 - accuracy: 0.9841 - val_loss: 0.0571 - val_accuracy: 0.9857 - 3s/epoch - 329ms/step\n",
            "Epoch 7/30\n",
            "9/9 - 3s - loss: 0.0279 - accuracy: 0.9942 - val_loss: 0.1039 - val_accuracy: 0.9695 - 3s/epoch - 316ms/step\n",
            "Epoch 8/30\n",
            "9/9 - 3s - loss: 0.0253 - accuracy: 0.9890 - val_loss: 0.0628 - val_accuracy: 0.9857 - 3s/epoch - 332ms/step\n",
            "Epoch 9/30\n",
            "9/9 - 3s - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.0779 - val_accuracy: 0.9821 - 3s/epoch - 330ms/step\n",
            "Epoch 10/30\n",
            "9/9 - 3s - loss: 0.0145 - accuracy: 0.9969 - val_loss: 0.0780 - val_accuracy: 0.9839 - 3s/epoch - 322ms/step\n",
            "Epoch 11/30\n",
            "9/9 - 3s - loss: 0.0111 - accuracy: 0.9955 - val_loss: 0.0711 - val_accuracy: 0.9839 - 3s/epoch - 334ms/step\n",
            "Epoch 12/30\n",
            "9/9 - 3s - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0759 - val_accuracy: 0.9830 - 3s/epoch - 339ms/step\n",
            "Epoch 13/30\n",
            "9/9 - 3s - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0757 - val_accuracy: 0.9883 - 3s/epoch - 368ms/step\n",
            "Epoch 14/30\n",
            "9/9 - 3s - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0803 - val_accuracy: 0.9865 - 3s/epoch - 338ms/step\n",
            "Epoch 15/30\n",
            "9/9 - 3s - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.0868 - val_accuracy: 0.9857 - 3s/epoch - 342ms/step\n",
            "Epoch 16/30\n",
            "9/9 - 3s - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.0847 - val_accuracy: 0.9857 - 3s/epoch - 344ms/step\n",
            "Epoch 17/30\n",
            "9/9 - 3s - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0869 - val_accuracy: 0.9901 - 3s/epoch - 368ms/step\n",
            "Epoch 18/30\n",
            "9/9 - 3s - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.0975 - val_accuracy: 0.9848 - 3s/epoch - 337ms/step\n",
            "Epoch 19/30\n",
            "9/9 - 3s - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.1090 - val_accuracy: 0.9749 - 3s/epoch - 344ms/step\n",
            "Epoch 20/30\n",
            "9/9 - 3s - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.0847 - val_accuracy: 0.9857 - 3s/epoch - 354ms/step\n",
            "Epoch 21/30\n",
            "9/9 - 3s - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0874 - val_accuracy: 0.9865 - 3s/epoch - 366ms/step\n",
            "Epoch 22/30\n",
            "9/9 - 3s - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.1031 - val_accuracy: 0.9794 - 3s/epoch - 360ms/step\n",
            "Epoch 23/30\n",
            "9/9 - 3s - loss: 0.0129 - accuracy: 0.9942 - val_loss: 0.0905 - val_accuracy: 0.9874 - 3s/epoch - 359ms/step\n",
            "Epoch 24/30\n",
            "9/9 - 3s - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.1127 - val_accuracy: 0.9812 - 3s/epoch - 357ms/step\n",
            "Epoch 25/30\n",
            "9/9 - 3s - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.1067 - val_accuracy: 0.9821 - 3s/epoch - 355ms/step\n",
            "Epoch 26/30\n",
            "9/9 - 3s - loss: 0.0058 - accuracy: 0.9975 - val_loss: 0.1111 - val_accuracy: 0.9865 - 3s/epoch - 343ms/step\n",
            "Epoch 27/30\n",
            "9/9 - 3s - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1185 - val_accuracy: 0.9794 - 3s/epoch - 340ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7eb1ebff9540>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "best_parameter_lstm_model=create_model(grid_model.best_params_['model__neurons'])\n",
        "\n",
        "earlystopping=callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=False)\n",
        "filepath='bestcheckpoint_nlp_spam_classification.hdf5'\n",
        "checkpoint=callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', mode='max', save_best_only=True)\n",
        "\n",
        "class_weights = compute_class_weight(class_weight='balanced',classes=np.unique(y_training), y=y_training)\n",
        "class_weight_dic = {0: class_weights[0], 1: class_weights[1]}\n",
        "\n",
        "best_parameter_lstm_model.fit(x_training_padded, array(y_training), validation_data = (x_test_padded, array(y_test)),\n",
        "                         batch_size = grid_model.best_params_['batch_size'],\n",
        "                         epochs = grid_model.best_params_['epochs'],\n",
        "                         verbose = 2, callbacks=[earlystopping, checkpoint], class_weight=class_weight_dic)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fc597e0",
      "metadata": {
        "id": "5fc597e0"
      },
      "source": [
        "Load the model again by the saved file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5d93096e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d93096e",
        "outputId": "be1667b7-3662-476f-c5d9-be301bd9e79c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0869 - accuracy: 0.9901\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08686558902263641, 0.9901345372200012]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "best_parameter_lstm_model.load_weights(filepath)\n",
        "best_parameter_lstm_model.evaluate(x_test_padded, array(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf40cc41",
      "metadata": {
        "id": "cf40cc41"
      },
      "source": [
        "Doing prediction for the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ca27b777",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca27b777",
        "outputId": "2d3f339d-304c-4004-bcde-a85aa1b89424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 1s 14ms/step\n",
            "The predicted label for test data: \n",
            "['ham' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n"
          ]
        }
      ],
      "source": [
        "predictions = best_parameter_lstm_model.predict(x_test_padded)\n",
        "predicted_labels = (predictions > 0.5).astype(np.int64)\n",
        "\n",
        "label_list=['ham','spam']\n",
        "predicted_label_list=[]\n",
        "for i in range(len(predicted_labels.reshape(1,-1)[0])):\n",
        "    predicted_label_list.append(label_list[predicted_labels.reshape(1,-1)[0][i]])\n",
        "\n",
        "print('The predicted label for test data: ')\n",
        "print(array(predicted_label_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86e9b7e4",
      "metadata": {
        "id": "86e9b7e4"
      },
      "source": [
        "Calculate the accuracy and the number of error of the prediction by the LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ce469827",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce469827",
        "outputId": "fcc946c5-2ac4-4965-da58-99959ef8ec31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "number of class 0 in test data: 962\n",
            "The num error of class 0:  2\n",
            "Accuracy of class 0:  0.997920997920998\n",
            "\n",
            "number of class 1 in test data: 153\n",
            "The num error of class 1:  9\n",
            "Accuracy of class 1:  0.9411764705882353\n",
            "\n",
            "\n",
            "The total num of error:  11\n",
            "The num of test data:  1115\n",
            "Total accuracy:  0.9901345291479821\n"
          ]
        }
      ],
      "source": [
        "error_num=0\n",
        "error_num_class_0=0\n",
        "error_num_class_1=0\n",
        "for i in range(len(array(y_test))):\n",
        "    if predicted_labels.reshape(1,-1)[0][i]!=array(y_test)[i]:\n",
        "        error_num+=1\n",
        "        if array(y_test)[i]==0:\n",
        "            error_num_class_0+=1\n",
        "        elif array(y_test)[i]==1:\n",
        "            error_num_class_1+=1\n",
        "\n",
        "\n",
        "print('')\n",
        "y_test_count = Counter(y_test)\n",
        "for element, count in y_test_count.items():\n",
        "  print(f'number of class {element} in test data: {count}')\n",
        "  if element==0:\n",
        "    print('The num error of class 0: ', error_num_class_0)\n",
        "    print('Accuracy of class 0: ', 1-error_num_class_0/count)\n",
        "  if element==1:\n",
        "    print('The num error of class 1: ', error_num_class_1)\n",
        "    print('Accuracy of class 1: ', 1-error_num_class_1/count)\n",
        "  print('')\n",
        "\n",
        "\n",
        "print('')\n",
        "print('The total num of error: ', error_num)\n",
        "print('The num of test data: ', len(array(y_test)))\n",
        "print('Total accuracy: ', 1-error_num/len(array(y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning BERT model"
      ],
      "metadata": {
        "id": "KBp0sevju_T8"
      },
      "id": "KBp0sevju_T8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training the LSTM model, lets try fine-tuning BERT model for Text Classification"
      ],
      "metadata": {
        "id": "vPaqWYYFvNsS"
      },
      "id": "vPaqWYYFvNsS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the pre-trained BERT model and Tokenizer from Huggingface"
      ],
      "metadata": {
        "id": "z9DSpMdkz8rh"
      },
      "id": "z9DSpMdkz8rh"
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcU-F65Az45p",
        "outputId": "f91fc0d7-4342-43d1-d56a-e9fa8aefbf96"
      },
      "id": "wcU-F65Az45p",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data processing again without using stopwords and Lemmatization"
      ],
      "metadata": {
        "id": "ZXUqBstzwcqS"
      },
      "id": "ZXUqBstzwcqS"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "ce9cad62",
      "metadata": {
        "id": "ce9cad62"
      },
      "outputs": [],
      "source": [
        "message=df.iloc[:,1].str.lower().copy()\n",
        "\n",
        "message=message.str.replace(r'[^ ]+@[^\\.]*(\\.[a-z]{2,}){1,2}', 'emailaddress', regex=True)\n",
        "message=message.str.replace(r'(?:http\\:\\/\\/|www.){1}(?:http\\:\\/\\/|www.)?(?![www])[a-zA-Z0-9\\-]+(\\.[a-zA-Z]{2,3}){1,2}(\\/[^/& ]+)*', 'webaddress', regex=True)\n",
        "message=message.str.replace(r'(£|\\$|€|¥|₣|å£){1}\\d+(.\\d+)?', 'money', regex=True)\n",
        "message=message.str.replace(r'\\b\\+?\\d{1}[\\d\\s-]{5,13}\\d{1}\\b|\\b[\\d]{4}[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}\\b', 'phonenumber', regex=True)\n",
        "\n",
        "# date\n",
        "# day/month/year\n",
        "message=message.str.replace(r'\\b(3[01]|[12][0-9]|[0]?[1-9]){1}[\\ |\\-|\\/]{1}(1[0-2]|[0]?[1-9]){1}[\\ |\\-|\\/]{1}(\\d{2}|\\d{4})(?!\\d{3})\\b', 'date', regex=True)\n",
        "# year/month/day\n",
        "message=message.str.replace(r'\\b(\\d{2}|\\d{4})(?!\\d{3})[\\ |\\-|\\/]{1}(1[0-2]|[0]?[1-9]){1}[\\ |\\-|\\/]{1}(3[01]|[12][0-9]|[0]?[1-9]){1}\\b', 'date', regex=True)\n",
        "# day/month(english)/year\n",
        "message=message.str.replace(r'\\b(3[01]|[12][0-9]|[0]?[1-9]){1}([\\ ]|st|nd|rd|th){1,2}(jan(?:uary)?|feb(?:ruary)?|mar(?:ch)?|apr(?:il)?|may|jun(?:e)?|jul(?:y)?|aug(?:ust)?|sep(?:tember)?|oct(?:ober)?|nov(?:ember)?|dec(?:ember)?){1}\\b(?:([\\ ]|,){0,2}(\\d{4}|\\d{2}))?\\b', 'date', regex=True)\n",
        "# month(english)/day/year\n",
        "message=message.str.replace(r'\\b(jan(?:uary)?|feb(?:ruary)?|mar(?:ch)?|apr(?:il)?|may|jun(?:e)?|jul(?:y)?|aug(?:ust)?|sep(?:tember)?|oct(?:ober)?|nov(?:ember)?|dec(?:ember)?){1}[\\ ]?(3[01]|[12][0-9]|[0]?[1-9]){1}((?: )?st|(?: )?nd|(?: )?rd|(?: )?th){0,1}(?:([\\ ]|,){0,2}(\\d{4}|\\d{2}))?\\b', 'date', regex=True)\n",
        "\n",
        "message=message.str.replace(r'\\b\\d+\\b', 'number', regex=True)\n",
        "message=message.str.replace(r'[^\\w\\d\\s\\']+', ' ', regex=True)\n",
        "message=message.str.replace(r'\\s+', ' ', regex=True)\n",
        "message=message.str.replace(r'^\\s+|\\s+?$', '', regex=True)\n",
        "\n",
        "df_message = list(zip(message, label))\n",
        "np.random.shuffle(df_message)\n",
        "message_split = [text[0] for text in df_message]\n",
        "list_label = [text[1] for text in df_message]\n",
        "x_training, x_test, y_training, y_test= train_test_split(message_split, list_label, test_size=0.2, random_state=1)\n",
        "\n",
        "max_len=0\n",
        "\n",
        "for i in range(len(x_training)):\n",
        "  if len(bert_tokenizer.tokenize(x_training[i]))>max_len:\n",
        "    max_len=len(bert_tokenizer.tokenize(x_training[i]))\n",
        "for i in range(len(x_test)):\n",
        "  if len(bert_tokenizer.tokenize(x_test[i]))>max_len:\n",
        "    max_len=len(bert_tokenizer.tokenize(x_test[i]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the data by the BERT Tokenizer and create train and test dataset"
      ],
      "metadata": {
        "id": "CmmpGfjr2ybr"
      },
      "id": "CmmpGfjr2ybr"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b91c39f2",
      "metadata": {
        "id": "b91c39f2"
      },
      "outputs": [],
      "source": [
        "# Train dataset\n",
        "tokens_training = bert_tokenizer.batch_encode_plus(x_training, max_length=max_len, padding='max_length', truncation=True)\n",
        "x_training_encoded = np.array(tokens_training['input_ids'])\n",
        "x_training_am = np.array(tokens_training['attention_mask'])\n",
        "\n",
        "# Test dataset\n",
        "tokens_test = bert_tokenizer.batch_encode_plus(x_test, max_length=max_len, padding='max_length', truncation=True)\n",
        "x_test_encoded = np.array(tokens_test['input_ids'])\n",
        "x_test_am = np.array(tokens_test['attention_mask'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine tune pre-trained Bert mdoel by defining model layers and model fitting"
      ],
      "metadata": {
        "id": "0O6PdIOL3ltL"
      },
      "id": "0O6PdIOL3ltL"
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer_1 = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
        "input_layer_2 = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name='attention_mask')\n",
        "\n",
        "hidden_layer_1 = bert_model([input_layer_1, input_layer_2])[1]\n",
        "hidden_layer_2 = Dense(256, activation='relu')(hidden_layer_1)\n",
        "dropout_layer = Dropout(0.1)(hidden_layer_2)\n",
        "output_layer = Dense(1, activation='sigmoid')(dropout_layer)\n",
        "\n",
        "model = tf.keras.Model(inputs=[input_layer_1, input_layer_2], outputs=output_layer)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdDzp2CK2yi0",
        "outputId": "3bce0b20-f72c-4c26-9628-dea38aecb2b5"
      },
      "id": "PdDzp2CK2yi0",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)      [(None, 198)]                0         []                            \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer  [(None, 198)]                0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel  TFBaseModelOutputWithPooli   1094822   ['input_ids[0][0]',           \n",
            " )                           ngAndCrossAttentions(last_   40         'attention_mask[0][0]']      \n",
            "                             hidden_state=(None, 198, 7                                           \n",
            "                             68),                                                                 \n",
            "                              pooler_output=(None, 768)                                           \n",
            "                             , past_key_values=None, hi                                           \n",
            "                             dden_states=None, attentio                                           \n",
            "                             ns=None, cross_attentions=                                           \n",
            "                             None)                                                                \n",
            "                                                                                                  \n",
            " dense_42 (Dense)            (None, 256)                  196864    ['tf_bert_model[0][1]']       \n",
            "                                                                                                  \n",
            " dropout_121 (Dropout)       (None, 256)                  0         ['dense_42[0][0]']            \n",
            "                                                                                                  \n",
            " dense_43 (Dense)            (None, 1)                    257       ['dropout_121[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109679361 (418.39 MB)\n",
            "Trainable params: 109679361 (418.39 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "earlystopping_ft=callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=3, restore_best_weights=False)\n",
        "filepath_ft='bestcheckpoint_fine_tune.hdf5'\n",
        "checkpoint_ft=callbacks.ModelCheckpoint(filepath_ft, monitor='val_accuracy', mode='max', save_best_only=True)\n",
        "\n",
        "model.fit([x_training_encoded, x_training_am], np.array(y_training), validation_data = ([x_test_encoded, x_test_am], np.array(y_test)),\n",
        "      batch_size = 16,\n",
        "      epochs = 15,\n",
        "      verbose = 2, callbacks=[earlystopping_ft, checkpoint_ft])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiHh3Ex_2ykr",
        "outputId": "663f4baf-bc15-45bd-9bd0-6b87a25f4049"
      },
      "id": "TiHh3Ex_2ykr",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "279/279 - 266s - loss: 0.0784 - accuracy: 0.9773 - val_loss: 0.0549 - val_accuracy: 0.9865 - 266s/epoch - 953ms/step\n",
            "Epoch 2/15\n",
            "279/279 - 225s - loss: 0.0211 - accuracy: 0.9937 - val_loss: 0.0449 - val_accuracy: 0.9901 - 225s/epoch - 808ms/step\n",
            "Epoch 3/15\n",
            "279/279 - 194s - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0936 - val_accuracy: 0.9865 - 194s/epoch - 696ms/step\n",
            "Epoch 4/15\n",
            "279/279 - 195s - loss: 0.0318 - accuracy: 0.9933 - val_loss: 0.0678 - val_accuracy: 0.9821 - 195s/epoch - 700ms/step\n",
            "Epoch 5/15\n",
            "279/279 - 195s - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.1064 - val_accuracy: 0.9839 - 195s/epoch - 699ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7eb208ca5000>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the model again by the saved file"
      ],
      "metadata": {
        "id": "rYXun0ncZ-OU"
      },
      "id": "rYXun0ncZ-OU"
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(filepath_ft)\n",
        "model.evaluate([x_test_encoded, x_test_am], np.array(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0FTrf9V5E5q",
        "outputId": "d2ccb79d-8847-4bed-91fe-9a3e8d482a62"
      },
      "id": "P0FTrf9V5E5q",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 15s 416ms/step - loss: 0.0449 - accuracy: 0.9901\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04493414983153343, 0.9901345372200012]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing prediction for the test data"
      ],
      "metadata": {
        "id": "9l4Ka3T8a2Jz"
      },
      "id": "9l4Ka3T8a2Jz"
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_ft = model.predict([x_test_encoded, x_test_am])\n",
        "predicted_labels_ft = (predictions_ft > 0.5).astype(np.int64)\n",
        "\n",
        "label_list=['ham','spam']\n",
        "predicted_label_list_ft=[]\n",
        "for i in range(len(predicted_labels_ft.reshape(1,-1)[0])):\n",
        "    predicted_label_list_ft.append(label_list[predicted_labels_ft.reshape(1,-1)[0][i]])\n",
        "\n",
        "print('The predicted label for test data: ')\n",
        "print(array(predicted_label_list_ft))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IenSy57q5E7m",
        "outputId": "6d0bc095-7b2d-4df6-eb7a-7e5c12676b50"
      },
      "id": "IenSy57q5E7m",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 20s 411ms/step\n",
            "The predicted label for test data: \n",
            "['ham' 'ham' 'ham' ... 'spam' 'ham' 'spam']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error_num=0\n",
        "error_num_class_0=0\n",
        "error_num_class_1=0\n",
        "for i in range(len(array(y_test))):\n",
        "  if predicted_labels_ft.reshape(1,-1)[0][i]!=array(y_test)[i]:\n",
        "    error_num+=1\n",
        "    if array(y_test)[i]==0:\n",
        "      error_num_class_0+=1\n",
        "    elif array(y_test)[i]==1:\n",
        "        error_num_class_1+=1\n",
        "\n",
        "\n",
        "print('')\n",
        "y_test_count = Counter(y_test)\n",
        "for element, count in y_test_count.items():\n",
        "  print(f'number of class {element} in test data: {count}')\n",
        "  if element==0:\n",
        "    print('The num error of class 0: ', error_num_class_0)\n",
        "    print('Accuracy of class 0: ', 1-error_num_class_0/count)\n",
        "  if element==1:\n",
        "    print('The num error of class 1: ', error_num_class_1)\n",
        "    print('Accuracy of class 1: ', 1-error_num_class_1/count)\n",
        "  print('')\n",
        "\n",
        "\n",
        "print('')\n",
        "print('The total num of error: ', error_num)\n",
        "print('The num of test data: ', len(array(y_test)))\n",
        "print('Total accuracy: ', 1-error_num/len(array(y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGaFKuBHap9E",
        "outputId": "36f3d64e-06ac-49a6-e105-75714988d7c3"
      },
      "id": "CGaFKuBHap9E",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "number of class 0 in test data: 953\n",
            "The num error of class 0:  1\n",
            "Accuracy of class 0:  0.9989506820566632\n",
            "\n",
            "number of class 1 in test data: 162\n",
            "The num error of class 1:  10\n",
            "Accuracy of class 1:  0.9382716049382716\n",
            "\n",
            "\n",
            "The total num of error:  11\n",
            "The num of test data:  1115\n",
            "Total accuracy:  0.9901345291479821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJHNgSGtap_U"
      },
      "id": "MJHNgSGtap_U",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "tf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}